{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: QtAgg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os as os\n",
    "import cv2\n",
    "import imghdr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as trans\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus_local = tf.config.experimental.list_logical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpus_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpeg','jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts:\n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print('Issue with image {}'.format(image_path))\n",
    "             #os.remove(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 442 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.2720588 , 0.24803922, 0.1452206 ],\n",
       "          [0.26102942, 0.23848039, 0.14166667],\n",
       "          [0.23192401, 0.21182598, 0.12420343],\n",
       "          ...,\n",
       "          [0.24442402, 0.20465687, 0.06709559],\n",
       "          [0.24963236, 0.20281863, 0.0646446 ],\n",
       "          [0.24908088, 0.19859068, 0.0598652 ]],\n",
       " \n",
       "         [[0.3071691 , 0.27677697, 0.1661152 ],\n",
       "          [0.28694853, 0.2574755 , 0.15110295],\n",
       "          [0.23180147, 0.20294118, 0.10147059],\n",
       "          ...,\n",
       "          [0.3204044 , 0.2740196 , 0.12493873],\n",
       "          [0.3060049 , 0.25655636, 0.10441177],\n",
       "          [0.29491422, 0.2463848 , 0.09148284]],\n",
       " \n",
       "         [[0.36629903, 0.32120097, 0.20012255],\n",
       "          [0.34178922, 0.29669118, 0.17561275],\n",
       "          [0.25447303, 0.20845588, 0.08921569],\n",
       "          ...,\n",
       "          [0.42457107, 0.36378676, 0.1911152 ],\n",
       "          [0.40098038, 0.34019607, 0.17058824],\n",
       "          [0.38805148, 0.32726717, 0.1576593 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.89393383, 0.8498162 , 0.571875  ],\n",
       "          [0.8802083 , 0.8360907 , 0.5581495 ],\n",
       "          [0.89368874, 0.84375   , 0.5682598 ],\n",
       "          ...,\n",
       "          [0.60042894, 0.55631125, 0.17126225],\n",
       "          [0.64240193, 0.60471815, 0.22058824],\n",
       "          [0.7531863 , 0.714951  , 0.33486518]],\n",
       " \n",
       "         [[0.86452204, 0.82775736, 0.5620711 ],\n",
       "          [0.8471201 , 0.81035537, 0.54650736],\n",
       "          [0.84681374, 0.80422795, 0.5458946 ],\n",
       "          ...,\n",
       "          [0.69601715, 0.61145836, 0.20680147],\n",
       "          [0.74105394, 0.6552696 , 0.27297795],\n",
       "          [0.85153186, 0.764277  , 0.39583334]],\n",
       " \n",
       "         [[0.81691176, 0.785049  , 0.52916664],\n",
       "          [0.81482846, 0.78039217, 0.5287377 ],\n",
       "          [0.8120711 , 0.7705882 , 0.5262868 ],\n",
       "          ...,\n",
       "          [0.75128675, 0.641973  , 0.22591911],\n",
       "          [0.7889706 , 0.6747549 , 0.28995097],\n",
       "          [0.86875   , 0.7500613 , 0.389951  ]]],\n",
       " \n",
       " \n",
       "        [[[0.15995711, 0.34800857, 0.29315257],\n",
       "          [0.08757659, 0.25916055, 0.20886949],\n",
       "          [0.01476716, 0.15779719, 0.12642463],\n",
       "          ...,\n",
       "          [0.00784314, 0.00784314, 0.00784314],\n",
       "          [0.00784314, 0.00784314, 0.00784314],\n",
       "          [0.00784314, 0.00784314, 0.00784314]],\n",
       " \n",
       "         [[0.13060279, 0.3137523 , 0.26134726],\n",
       "          [0.06358379, 0.23017961, 0.18233953],\n",
       "          [0.00553768, 0.141502  , 0.11243681],\n",
       "          ...,\n",
       "          [0.00784314, 0.00784314, 0.00784314],\n",
       "          [0.00784314, 0.00784314, 0.00784314],\n",
       "          [0.00784314, 0.00784314, 0.00784314]],\n",
       " \n",
       "         [[0.08807636, 0.25949565, 0.21148515],\n",
       "          [0.03216146, 0.18967524, 0.14472465],\n",
       "          [0.        , 0.12039101, 0.09279642],\n",
       "          ...,\n",
       "          [0.00784314, 0.00784314, 0.00784314],\n",
       "          [0.00784314, 0.00784314, 0.00784314],\n",
       "          [0.00784314, 0.00784314, 0.00784314]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]]],\n",
       " \n",
       " \n",
       "        [[[0.51819855, 0.38878676, 0.3221201 ],\n",
       "          [0.4742647 , 0.3428309 , 0.27414215],\n",
       "          [0.4071691 , 0.2699142 , 0.19371936],\n",
       "          ...,\n",
       "          [0.18318015, 0.06161152, 0.        ],\n",
       "          [0.202788  , 0.07830882, 0.02328431],\n",
       "          [0.22576593, 0.10027573, 0.04929534]],\n",
       " \n",
       "         [[0.47397557, 0.3445638 , 0.27789715],\n",
       "          [0.47211292, 0.34067908, 0.27199036],\n",
       "          [0.4302452 , 0.2929903 , 0.21679544],\n",
       "          ...,\n",
       "          [0.18291304, 0.0613444 , 0.        ],\n",
       "          [0.1980689 , 0.07499952, 0.01341577],\n",
       "          [0.21485859, 0.09126791, 0.03078996]],\n",
       " \n",
       "         [[0.4260163 , 0.29660454, 0.22993787],\n",
       "          [0.4651262 , 0.33397672, 0.265288  ],\n",
       "          [0.451428  , 0.31551298, 0.23908117],\n",
       "          ...,\n",
       "          [0.18585995, 0.0661827 , 0.        ],\n",
       "          [0.19416551, 0.0742513 , 0.00250124],\n",
       "          [0.2017827 , 0.08186849, 0.00953106]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.56267667, 0.46105286, 0.3711938 ],\n",
       "          [0.44121382, 0.34216356, 0.26498833],\n",
       "          [0.43127584, 0.33437023, 0.29181507],\n",
       "          ...,\n",
       "          [0.70469373, 0.51357853, 0.20555156],\n",
       "          [0.87244225, 0.7378528 , 0.3199913 ],\n",
       "          [0.8301471 , 0.7297488 , 0.24001226]],\n",
       " \n",
       "         [[0.5305937 , 0.42896992, 0.33911085],\n",
       "          [0.4575095 , 0.35845923, 0.28128397],\n",
       "          [0.3603056 , 0.26339996, 0.22084482],\n",
       "          ...,\n",
       "          [0.7104669 , 0.52050495, 0.21247798],\n",
       "          [0.87392867, 0.7398605 , 0.32199898],\n",
       "          [0.8277473 , 0.72734904, 0.2376125 ]],\n",
       " \n",
       "         [[0.4964767 , 0.39485294, 0.30499387],\n",
       "          [0.47708333, 0.3780331 , 0.30085784],\n",
       "          [0.2799326 , 0.18302695, 0.14047182],\n",
       "          ...,\n",
       "          [0.7134498 , 0.52457106, 0.21654412],\n",
       "          [0.8749081 , 0.74132967, 0.32346815],\n",
       "          [0.826011  , 0.72561276, 0.23587623]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[1.        , 0.99607843, 0.95686275],\n",
       "          [0.9797794 , 0.96574754, 0.92316175],\n",
       "          [0.9764706 , 0.95778185, 0.92965686],\n",
       "          ...,\n",
       "          [0.9219363 , 0.93694854, 0.9170956 ],\n",
       "          [1.        , 1.        , 0.99215686],\n",
       "          [1.        , 1.        , 0.99215686]],\n",
       " \n",
       "         [[0.93949145, 0.9174173 , 0.8842524 ],\n",
       "          [0.9868703 , 0.9806856 , 0.9441507 ],\n",
       "          [0.9946232 , 0.9903525 , 0.96132934],\n",
       "          ...,\n",
       "          [0.42571867, 0.4407309 , 0.42087796],\n",
       "          [0.9887492 , 0.9887492 , 0.98090607],\n",
       "          [0.9939491 , 0.9939491 , 0.986106  ]],\n",
       " \n",
       "         [[0.97012866, 0.9572457 , 0.93072915],\n",
       "          [0.9853665 , 0.97312206, 0.945322  ],\n",
       "          [0.64023834, 0.6318162 , 0.60795206],\n",
       "          ...,\n",
       "          [0.12778428, 0.13721971, 0.12480253],\n",
       "          [0.53244245, 0.53244245, 0.5245993 ],\n",
       "          [0.9314568 , 0.9314568 , 0.92361367]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.99607843, 0.9882353 , 1.        ],\n",
       "          [0.98147905, 0.9757225 , 0.98588115],\n",
       "          [0.8426662 , 0.83653563, 0.84185743],\n",
       "          ...,\n",
       "          [0.41876113, 0.41876113, 0.41876113],\n",
       "          [0.7840051 , 0.7840051 , 0.7840051 ],\n",
       "          [0.96265316, 0.96265316, 0.96265316]],\n",
       " \n",
       "         [[0.9969746 , 0.99002755, 1.        ],\n",
       "          [0.9631749 , 0.95622784, 0.97140026],\n",
       "          [0.9900728 , 0.9861283 , 0.9922001 ],\n",
       "          ...,\n",
       "          [0.8540703 , 0.8540703 , 0.8540703 ],\n",
       "          [0.99489456, 0.99489456, 0.99489456],\n",
       "          [0.9636949 , 0.9636949 , 0.9636949 ]],\n",
       " \n",
       "         [[1.        , 0.99607843, 1.        ],\n",
       "          [1.        , 0.99607843, 1.        ],\n",
       "          [1.        , 0.9990809 , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]]],\n",
       " \n",
       " \n",
       "        [[[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]]],\n",
       " \n",
       " \n",
       "        [[[0.3409314 , 0.33700982, 0.32907474],\n",
       "          [0.30906862, 0.30533087, 0.28489584],\n",
       "          [0.278125  , 0.28235295, 0.22637868],\n",
       "          ...,\n",
       "          [0.3582414 , 0.47527573, 0.576777  ],\n",
       "          [0.32239583, 0.45153186, 0.57264096],\n",
       "          [0.30989584, 0.4509804 , 0.58422184]],\n",
       " \n",
       "         [[0.3236284 , 0.34968957, 0.35671663],\n",
       "          [0.3148233 , 0.34342867, 0.3357709 ],\n",
       "          [0.31635934, 0.34824866, 0.3173413 ],\n",
       "          ...,\n",
       "          [0.35315   , 0.46279106, 0.5667892 ],\n",
       "          [0.31252512, 0.443924  , 0.55777633],\n",
       "          [0.2999081 , 0.44101214, 0.574195  ]],\n",
       " \n",
       "         [[0.2982964 , 0.36311275, 0.38334218],\n",
       "          [0.30421823, 0.37139043, 0.37886748],\n",
       "          [0.32579657, 0.39352107, 0.3895953 ],\n",
       "          ...,\n",
       "          [0.35327902, 0.4572755 , 0.5596039 ],\n",
       "          [0.31149867, 0.4396196 , 0.55077   ],\n",
       "          [0.29578093, 0.43685985, 0.5669513 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.43063402, 0.5569635 , 0.7473225 ],\n",
       "          [0.42827818, 0.55614275, 0.74189645],\n",
       "          [0.42827818, 0.55614275, 0.7417756 ],\n",
       "          ...,\n",
       "          [0.42126226, 0.5655331 , 0.76006436],\n",
       "          [0.41894352, 0.56321436, 0.7577456 ],\n",
       "          [0.41888785, 0.5631587 , 0.75768995]],\n",
       " \n",
       "         [[0.43526348, 0.5646753 , 0.74114585],\n",
       "          [0.43137255, 0.56078434, 0.7372549 ],\n",
       "          [0.43137255, 0.56078434, 0.7372549 ],\n",
       "          ...,\n",
       "          [0.42745098, 0.5686275 , 0.7647059 ],\n",
       "          [0.42362133, 0.5647978 , 0.76087624],\n",
       "          [0.42352942, 0.5647059 , 0.7607843 ]],\n",
       " \n",
       "         [[0.43526348, 0.5646753 , 0.74114585],\n",
       "          [0.43137255, 0.56078434, 0.7372549 ],\n",
       "          [0.43137255, 0.56078434, 0.7372549 ],\n",
       "          ...,\n",
       "          [0.42745098, 0.5686275 , 0.7647059 ],\n",
       "          [0.42362133, 0.5647978 , 0.76087624],\n",
       "          [0.42352942, 0.5647059 , 0.7607843 ]]]], dtype=float32),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)\n",
    "test_size = int(len(data)*.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               3686656   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,696,625\n",
      "Trainable params: 3,696,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 10s 862ms/step - loss: 1.0635 - accuracy: 0.5382 - val_loss: 0.7457 - val_accuracy: 0.4688\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 9s 868ms/step - loss: 0.6528 - accuracy: 0.6493 - val_loss: 0.6778 - val_accuracy: 0.6094\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 9s 880ms/step - loss: 0.6533 - accuracy: 0.6493 - val_loss: 0.6762 - val_accuracy: 0.5781\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 8s 872ms/step - loss: 0.6619 - accuracy: 0.6111 - val_loss: 0.6502 - val_accuracy: 0.6562\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 8s 826ms/step - loss: 0.6604 - accuracy: 0.6250 - val_loss: 0.6489 - val_accuracy: 0.5938\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 8s 822ms/step - loss: 0.6670 - accuracy: 0.6736 - val_loss: 0.6530 - val_accuracy: 0.7656\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 8s 815ms/step - loss: 0.6550 - accuracy: 0.6389 - val_loss: 0.6481 - val_accuracy: 0.6875\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 8s 814ms/step - loss: 0.6401 - accuracy: 0.6389 - val_loss: 0.6469 - val_accuracy: 0.5938\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 8s 821ms/step - loss: 0.6072 - accuracy: 0.6736 - val_loss: 0.5742 - val_accuracy: 0.6406\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 8s 844ms/step - loss: 0.5894 - accuracy: 0.6771 - val_loss: 0.5822 - val_accuracy: 0.6719\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 8s 832ms/step - loss: 0.5557 - accuracy: 0.7153 - val_loss: 0.4590 - val_accuracy: 0.7344\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 8s 845ms/step - loss: 0.5474 - accuracy: 0.7083 - val_loss: 0.5520 - val_accuracy: 0.6719\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 8s 844ms/step - loss: 0.5970 - accuracy: 0.7465 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 9s 956ms/step - loss: 0.5521 - accuracy: 0.6701 - val_loss: 0.5757 - val_accuracy: 0.7031\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.5827 - accuracy: 0.6875 - val_loss: 0.5903 - val_accuracy: 0.6562\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.5566 - accuracy: 0.6701 - val_loss: 0.5797 - val_accuracy: 0.5781\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 9s 920ms/step - loss: 0.5232 - accuracy: 0.6910 - val_loss: 0.6632 - val_accuracy: 0.5469\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.5063 - accuracy: 0.7674 - val_loss: 0.4530 - val_accuracy: 0.7656\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 8s 827ms/step - loss: 0.4555 - accuracy: 0.8021 - val_loss: 0.5411 - val_accuracy: 0.6719\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 8s 807ms/step - loss: 0.5151 - accuracy: 0.7569 - val_loss: 0.5259 - val_accuracy: 0.6719\n"
     ]
    }
   ],
   "source": [
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [36]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m prediction_NN \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mval_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m prediction_NN \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(prediction_NN, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      3\u001B[0m prediction_NN \u001B[38;5;241m=\u001B[39m le\u001B[38;5;241m.\u001B[39minverse_transform(prediction_NN)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:910\u001B[0m, in \u001B[0;36mTensorShape.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    908\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    909\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_v2_behavior:\n\u001B[1;32m--> 910\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dims\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    911\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    912\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdims[key]\n",
      "\u001B[1;31mIndexError\u001B[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "prediction_NN = model.predict(val_size)\n",
    "prediction_NN = np.argmax(prediction_NN, axis=-1)\n",
    "prediction_NN = le.inverse_transform(prediction_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_NN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [35]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#Confusion Matrix - verify accuracy of each class\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m confusion_matrix\n\u001B[1;32m----> 3\u001B[0m cm \u001B[38;5;241m=\u001B[39m confusion_matrix(test_size, \u001B[43mprediction_NN\u001B[49m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(cm)\n\u001B[0;32m      5\u001B[0m sns\u001B[38;5;241m.\u001B[39mheatmap(cm, annot\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'prediction_NN' is not defined"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix - verify accuracy of each class\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_size, prediction_NN)\n",
    "print(cm)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
